{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to parse SEC Edgar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_date_arg(value, arg_name=None):\n",
    "    if value:\n",
    "        try:\n",
    "            if len(value) != 8:\n",
    "                raise ValueError\n",
    "            datetime.strptime(value, '%Y%m%d')\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Option '%s' must be in YYYYMMDD format, input is '%s'\" % (arg_name, value))\n",
    "\n",
    "def parse_limit_arg(value):\n",
    "    if value:\n",
    "        tokens = value.split(',')\n",
    "        try:\n",
    "            if len(tokens) != 2:\n",
    "                raise ValueError\n",
    "            return int(tokens[0]), int(tokens[1])\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Option 'limit' must be in START,COUNT format, input is '%s'\" % value)\n",
    "    return 0, None\n",
    "\n",
    "\n",
    "def load_symbols(file_path):\n",
    "    symbols = []\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#'):\n",
    "                symbol = line.split()[0]\n",
    "                symbols.append(symbol)\n",
    "    return symbols\n",
    "\n",
    "def get_symbol(values):\n",
    "    if values:\n",
    "        symbols = map(lambda s: s.strip(), values[0].split(','))\n",
    "        return '/'.join(symbols)\n",
    "    return False\n",
    "\n",
    "def parse_csv(file_like):\n",
    "    reader = csv.reader(file_like)\n",
    "    headers = reader.next()\n",
    "    for row in reader:\n",
    "        item = {}\n",
    "        for i, value in enumerate(row):\n",
    "            header = headers[i]\n",
    "            item[header] = value\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: UserWarning: You do not have a working installation of the service_identity module: 'cannot import name 'verify_ip_address''.  Please install it from <https://pypi.python.org/pypi/service_identity> and make sure all of its dependencies are satisfied.  Without the service_identity module, Twisted can perform only rudimentary TLS client hostname verification.  Many valid certificate/hostname mappings may be rejected.\n"
     ]
    }
   ],
   "source": [
    "from scrapy.loader import ItemLoader\n",
    "from pystock_crawler.items import ReportItem\n",
    "from scrapy.loader.processors import Compose, MapCompose, TakeFirst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_bool(value):\n",
    "    if hasattr(value, 'lower'):\n",
    "        value = value.lower()\n",
    "        return bool(value) and value != 'false' and value != '0'\n",
    "    return bool(value)\n",
    "\n",
    "def get_amend(values):\n",
    "    if values:\n",
    "        return values[0]\n",
    "    return False\n",
    "\n",
    "def imd_filter_member(imd_values):\n",
    "    if imd_values:\n",
    "        with_memberness = [(v, memberness(v.context)) for v in imd_values]\n",
    "        with_memberness = sorted(with_memberness, cmp=lambda a, b: a[1] - b[1])\n",
    "\n",
    "        m0 = with_memberness[0][1]\n",
    "        non_members = []\n",
    "\n",
    "        for v in with_memberness:\n",
    "            if v[1] == m0:\n",
    "                non_members.append(v[0])\n",
    "\n",
    "        return non_members\n",
    "\n",
    "    return imd_values\n",
    "\n",
    "def imd_max(imd_values):\n",
    "    if imd_values:\n",
    "        imd_value = max(imd_values)\n",
    "        return imd_value.value\n",
    "    return None\n",
    "\n",
    "\n",
    "def imd_min(imd_values):\n",
    "    if imd_values:\n",
    "        imd_value = min(imd_values)\n",
    "        return imd_value.value\n",
    "    return None\n",
    "\n",
    "def imd_mult(imd_values):\n",
    "    for v in imd_values:\n",
    "        try:\n",
    "            node_id = v.node.xpath('@id')[0].extract().lower()\n",
    "        except (AttributeError, IndexError):\n",
    "            pass\n",
    "        else:\n",
    "            # HACK: some of LUV's reports have unreasonablely small numbers such as\n",
    "            # 4136 in revenues which should be 4136 millions, this hack uses id attribute\n",
    "            # to determine if it should be scaled up\n",
    "            if 'inmillions' in node_id and abs(v.value) < 100000.0:\n",
    "                v.value *= 1000000.0\n",
    "            elif 'inthousands' in node_id and abs(v.value) < 100000000.0:\n",
    "                v.value *= 1000.0\n",
    "    return imd_values\n",
    "\n",
    "def imd_get_revenues(imd_values):\n",
    "    interest_elems = filter(lambda v: 'interest' in v.local_name.lower(), imd_values)\n",
    "    if len(interest_elems) == len(imd_values):\n",
    "        # HACK: An exceptional case for BBT\n",
    "        # Revenues = InterestIncome + NoninterestIncome\n",
    "        return imd_sum(imd_values)\n",
    "\n",
    "    return imd_max(imd_values)\n",
    "\n",
    "def imd_get_net_income(imd_values):\n",
    "    return imd_min(imd_values)\n",
    "\n",
    "def imd_get_op_income(imd_values):\n",
    "    imd_values = filter(lambda v: memberness(v.context) < 2, imd_values)\n",
    "    return imd_min(imd_values)\n",
    "\n",
    "def imd_get_cash_flow(imd_values, loader_context):\n",
    "    if len(imd_values) == 1:\n",
    "        return imd_values[0].value\n",
    "\n",
    "    doc_type = loader_context['doc_type']\n",
    "\n",
    "    within_date_range = []\n",
    "    for imd_value in imd_values:\n",
    "        if imd_value.start_date and imd_value.end_date:\n",
    "            if date_range_matches_doc_type(doc_type, imd_value.start_date, imd_value.end_date):\n",
    "                within_date_range.append(imd_value)\n",
    "\n",
    "    if within_date_range:\n",
    "        return imd_max(within_date_range)\n",
    "\n",
    "    return imd_max(imd_values)\n",
    "\n",
    "\n",
    "def imd_get_per_share_value(imd_values):\n",
    "    if not imd_values:\n",
    "        return None\n",
    "\n",
    "    v = imd_values[0]\n",
    "    value = v.value\n",
    "    if abs(value) > MAX_PER_SHARE_VALUE:\n",
    "        try:\n",
    "            decimals = int(v.node.xpath('@decimals')[0].extract())\n",
    "        except (AttributeError, IndexError, ValueError):\n",
    "            return None\n",
    "        else:\n",
    "            # HACK: some of LTD's reports have unreasonablely large per share value, such as\n",
    "            # 320000 EPS (and it should be 0.32), so use decimals attribute to scale it down,\n",
    "            # note that this is NOT a correct way to interpret decimals attribute\n",
    "            value *= pow(10, decimals - 2)\n",
    "    return value if abs(value) <= MAX_PER_SHARE_VALUE else None\n",
    "\n",
    "\n",
    "def imd_get_equity(imd_values):\n",
    "    if not imd_values:\n",
    "        return None\n",
    "\n",
    "    values = filter(lambda v: v.local_name == 'StockholdersEquityIncludingPortionAttributableToNoncontrollingInterest', imd_values)\n",
    "    if values:\n",
    "        return values[0].value\n",
    "\n",
    "    values = filter(lambda v: v.local_name == 'StockholdersEquity', imd_values)\n",
    "    if values:\n",
    "        return values[0].value\n",
    "\n",
    "    return imd_values[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XmlXPathItemLoader(ItemLoader):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(XmlXPathItemLoader, self).__init__(*args, **kwargs)\n",
    "        register_namespaces(self.selector)\n",
    "\n",
    "    def add_xpath(self, field_name, xpath, *processors, **kw):\n",
    "        values = self._get_values(xpath, **kw)\n",
    "        self.add_value(field_name, values, *processors, **kw)\n",
    "        return len(self._values[field_name])\n",
    "\n",
    "    def add_xpaths(self, name, paths):\n",
    "        for path in paths:\n",
    "            match_count = self.add_xpath(name, path)\n",
    "            if match_count > 0:\n",
    "                return match_count\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def _get_values(self, xpaths, **kw):\n",
    "        xpaths = arg_to_iter(xpaths)\n",
    "        return flatten([self.selector.xpath(xpath) for xpath in xpaths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractText(object):\n",
    "\n",
    "    def __call__(self, value):\n",
    "        if hasattr(value, 'select'):\n",
    "            try:\n",
    "                return value.xpath('./text()')[0].extract()\n",
    "            except IndexError:\n",
    "                return ''\n",
    "        return str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchEndDate(object):\n",
    "\n",
    "    def __init__(self, data_type=str, ignore_date_range=False):\n",
    "        self.data_type = data_type\n",
    "        self.ignore_date_range = ignore_date_range\n",
    "\n",
    "    def __call__(self, value, loader_context):\n",
    "        if not hasattr(value, 'select'):\n",
    "            return IntermediateValue('', 0.0, '0', None)\n",
    "\n",
    "        doc_end_date_str = loader_context['end_date']\n",
    "        doc_type = loader_context['doc_type']\n",
    "        selector = loader_context['selector']\n",
    "\n",
    "        context_id = value.xpath('@contextRef')[0].extract()\n",
    "        try:\n",
    "            context = selector.xpath('//*[@id=\"%s\"]' % context_id)[0]\n",
    "        except IndexError:\n",
    "            try:\n",
    "                url = loader_context['response'].url\n",
    "            except KeyError:\n",
    "                url = None\n",
    "            log.msg(u'Cannot find context: %s in %s' % (context_id, url), log.WARNING)\n",
    "            return None\n",
    "\n",
    "        date = instant = start_date = end_date = None\n",
    "        try:\n",
    "            instant = context.xpath('.//*[local-name()=\"instant\"]/text()')[0].extract().strip()\n",
    "        except (IndexError, ValueError):\n",
    "            try:\n",
    "                end_date_str = context.xpath('.//*[local-name()=\"endDate\"]/text()')[0].extract().strip()\n",
    "                end_date = datetime.strptime(end_date_str, DATE_FORMAT)\n",
    "\n",
    "                start_date_str = context.xpath('.//*[local-name()=\"startDate\"]/text()')[0].extract().strip()\n",
    "                start_date = datetime.strptime(start_date_str, DATE_FORMAT)\n",
    "\n",
    "                if self.ignore_date_range or date_range_matches_doc_type(doc_type, start_date, end_date):\n",
    "                    date = end_date\n",
    "            except (IndexError, ValueError):\n",
    "                pass\n",
    "        else:\n",
    "            try:\n",
    "                instant = datetime.strptime(instant, DATE_FORMAT)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            else:\n",
    "                date = instant\n",
    "\n",
    "        if date:\n",
    "            doc_end_date = datetime.strptime(doc_end_date_str, DATE_FORMAT)\n",
    "            delta_days = (doc_end_date - date).days\n",
    "            if abs(delta_days) < 30:\n",
    "                try:\n",
    "                    text = value.xpath('./text()')[0].extract()\n",
    "                    val = self.data_type(text)\n",
    "                except (IndexError, ValueError):\n",
    "                    pass\n",
    "                else:\n",
    "                    local_name = value.xpath('local-name()')[0].extract()\n",
    "                    return IntermediateValue(\n",
    "                        local_name, val, text, context, value,\n",
    "                        start_date=start_date, end_date=end_date, instant=instant)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdSumMembersOr(object):\n",
    "\n",
    "    def __init__(self, second_func=None):\n",
    "        self.second_func = second_func\n",
    "\n",
    "    def __call__(self, imd_values):\n",
    "        members = []\n",
    "        non_members = []\n",
    "        for imd_value in imd_values:\n",
    "            if imd_value.is_member():\n",
    "                members.append(imd_value)\n",
    "            else:\n",
    "                non_members.append(imd_value)\n",
    "\n",
    "        if members and len(members) == len(imd_values):\n",
    "            return imd_sum(members)\n",
    "\n",
    "        if imd_values:\n",
    "            return self.second_func(non_members)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportItemLoader(XmlXPathItemLoader):\n",
    "\n",
    "    default_item_class = ReportItem\n",
    "    default_output_processor = TakeFirst()\n",
    "\n",
    "    symbol_in = MapCompose(ExtractText(), str.upper)\n",
    "    symbol_out = Compose(get_symbol)\n",
    "\n",
    "    amend_in = MapCompose(ExtractText(), str_to_bool)\n",
    "    amend_out = Compose(get_amend)\n",
    "\n",
    "    period_focus_in = MapCompose(ExtractText(), str.upper)\n",
    "    period_focus_out = TakeFirst()\n",
    "\n",
    "    revenues_in = MapCompose(MatchEndDate(float))\n",
    "    revenues_out = Compose(imd_filter_member, imd_mult, ImdSumMembersOr(imd_get_revenues))\n",
    "\n",
    "    net_income_in = MapCompose(MatchEndDate(float))\n",
    "    net_income_out = Compose(imd_filter_member, imd_mult, imd_get_net_income)\n",
    "\n",
    "    op_income_in = MapCompose(MatchEndDate(float))\n",
    "    op_income_out = Compose(imd_filter_member, imd_mult, imd_get_op_income)\n",
    "\n",
    "    eps_basic_in = MapCompose(MatchEndDate(float))\n",
    "    eps_basic_out = Compose(ImdSumMembersOr(imd_get_per_share_value), lambda x: x if x < MAX_PER_SHARE_VALUE else None)\n",
    "\n",
    "    eps_diluted_in = MapCompose(MatchEndDate(float))\n",
    "    eps_diluted_out = Compose(ImdSumMembersOr(imd_get_per_share_value), lambda x: x if x < MAX_PER_SHARE_VALUE else None)\n",
    "\n",
    "    dividend_in = MapCompose(MatchEndDate(float))\n",
    "    dividend_out = Compose(imd_get_per_share_value, lambda x: x if x < MAX_PER_SHARE_VALUE and x > 0.0 else 0.0)\n",
    "\n",
    "    assets_in = MapCompose(MatchEndDate(float))\n",
    "    assets_out = Compose(imd_filter_member, imd_mult, imd_max)\n",
    "\n",
    "    cur_assets_in = MapCompose(MatchEndDate(float))\n",
    "    cur_assets_out = Compose(imd_filter_member, imd_mult, imd_max)\n",
    "\n",
    "    cur_liab_in = MapCompose(MatchEndDate(float))\n",
    "    cur_liab_out = Compose(imd_filter_member, imd_mult, imd_max)\n",
    "\n",
    "    equity_in = MapCompose(MatchEndDate(float))\n",
    "    equity_out = Compose(imd_filter_member, imd_mult, imd_get_equity)\n",
    "\n",
    "    cash_in = MapCompose(MatchEndDate(float))\n",
    "    cash_out = Compose(imd_filter_member, imd_mult, imd_max)\n",
    "\n",
    "    cash_flow_op_in = MapCompose(MatchEndDate(float, True))\n",
    "    cash_flow_op_out = Compose(imd_filter_member, imd_mult, imd_get_cash_flow)\n",
    "\n",
    "    cash_flow_inv_in = MapCompose(MatchEndDate(float, True))\n",
    "    cash_flow_inv_out = Compose(imd_filter_member, imd_mult, imd_get_cash_flow)\n",
    "\n",
    "    cash_flow_fin_in = MapCompose(MatchEndDate(float, True))\n",
    "    cash_flow_fin_out = Compose(imd_filter_member, imd_mult, imd_get_cash_flow)\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        response = kwargs.get('response')\n",
    "        if len(response.body) > THRESHOLD_TO_CLEAN:\n",
    "            # Remove some useless text to reduce memory usage\n",
    "            body, __ = RE_XML_GARBAGE.subn(lambda m: '><', response.body)\n",
    "            response = response.replace(body=body)\n",
    "            kwargs['response'] = response\n",
    "\n",
    "        super(ReportItemLoader, self).__init__(*args, **kwargs)\n",
    "\n",
    "        symbol = self._get_symbol()\n",
    "        end_date = self._get_doc_end_date()\n",
    "        fiscal_year = self._get_doc_fiscal_year()\n",
    "        doc_type = self._get_doc_type()\n",
    "\n",
    "        # ignore document that is not 10-Q or 10-K\n",
    "        if not (doc_type and doc_type.split('/')[0] in ('10-Q', '10-K')):\n",
    "            return\n",
    "\n",
    "        # some documents set their amendment flag in DocumentType, e.g., '10-Q/A',\n",
    "        # instead of setting it in AmendmentFlag\n",
    "        amend = None\n",
    "        if doc_type.endswith('/A'):\n",
    "            amend = True\n",
    "            doc_type = doc_type[0:-2]\n",
    "\n",
    "        self.context.update({\n",
    "            'end_date': end_date,\n",
    "            'doc_type': doc_type\n",
    "        })\n",
    "\n",
    "        self.add_xpath('symbol', '//dei:TradingSymbol')\n",
    "        self.add_value('symbol', symbol)\n",
    "\n",
    "        if amend:\n",
    "            self.add_value('amend', True)\n",
    "        else:\n",
    "            self.add_xpath('amend', '//dei:AmendmentFlag')\n",
    "\n",
    "        if doc_type == '10-K':\n",
    "            period_focus = 'FY'\n",
    "        else:\n",
    "            period_focus = self._get_period_focus(end_date)\n",
    "\n",
    "        if not fiscal_year and period_focus:\n",
    "            fiscal_year = self._guess_fiscal_year(end_date, period_focus)\n",
    "\n",
    "        self.add_value('period_focus', period_focus)\n",
    "        self.add_value('fiscal_year', fiscal_year)\n",
    "        self.add_value('end_date', end_date)\n",
    "        self.add_value('doc_type', doc_type)\n",
    "\n",
    "        self.add_xpaths('revenues', [\n",
    "            '//us-gaap:SalesRevenueNet',\n",
    "            '//us-gaap:Revenues',\n",
    "            '//us-gaap:SalesRevenueGoodsNet',\n",
    "            '//us-gaap:SalesRevenueServicesNet',\n",
    "            '//us-gaap:RealEstateRevenueNet',\n",
    "            '//*[local-name()=\"NetRevenuesIncludingNetInterestIncome\"]',\n",
    "            '//*[contains(local-name(), \"TotalRevenues\") and contains(local-name(), \"After\")]',\n",
    "            '//*[contains(local-name(), \"TotalRevenues\")]',\n",
    "            '//*[local-name()=\"InterestAndDividendIncomeOperating\" or local-name()=\"NoninterestIncome\"]',\n",
    "            '//*[contains(local-name(), \"Revenue\")]'\n",
    "        ])\n",
    "        self.add_xpath('revenues', '//us-gaap:FinancialServicesRevenue')\n",
    "\n",
    "        self.add_xpaths('net_income', [\n",
    "            '//*[contains(local-name(), \"NetLossIncome\") and contains(local-name(), \"Corporation\")]',\n",
    "            '//*[local-name()=\"NetIncomeLossAvailableToCommonStockholdersBasic\" or local-name()=\"NetIncomeLoss\"]',\n",
    "            '//us-gaap:ProfitLoss',\n",
    "            '//us-gaap:IncomeLossFromContinuingOperations',\n",
    "            '//*[contains(local-name(), \"IncomeLossFromContinuingOperations\") and not(contains(local-name(), \"Per\"))]',\n",
    "            '//*[contains(local-name(), \"NetIncomeLoss\")]',\n",
    "            '//*[starts-with(local-name(), \"NetIncomeAttributableTo\")]'\n",
    "        ])\n",
    "\n",
    "        self.add_xpaths('op_income', [\n",
    "            '//us-gaap:OperatingIncomeLoss'\n",
    "        ])\n",
    "\n",
    "        self.add_xpaths('eps_basic', [\n",
    "            '//us-gaap:EarningsPerShareBasic',\n",
    "            '//us-gaap:IncomeLossFromContinuingOperationsPerBasicShare',\n",
    "            '//us-gaap:IncomeLossFromContinuingOperationsPerBasicAndDilutedShare',\n",
    "            '//*[contains(local-name(), \"NetIncomeLoss\") and contains(local-name(), \"Per\") and contains(local-name(), \"Common\")]',\n",
    "            '//*[contains(local-name(), \"Earnings\") and contains(local-name(), \"Per\") and contains(local-name(), \"Basic\")]',\n",
    "            '//*[local-name()=\"IncomePerShareFromContinuingOperationsAvailableToCompanyStockholdersBasicAndDiluted\"]',\n",
    "            '//*[contains(local-name(), \"NetLossPerShare\")]',\n",
    "            '//*[contains(local-name(), \"NetIncome\") and contains(local-name(), \"Per\") and contains(local-name(), \"Basic\")]',\n",
    "            '//*[local-name()=\"BasicEarningsAttributableToStockholdersPerCommonShare\"]',\n",
    "            '//*[local-name()=\"Earningspersharebasicanddiluted\"]',\n",
    "            '//*[contains(local-name(), \"PerCommonShareBasicAndDiluted\")]',\n",
    "            '//*[local-name()=\"NetIncomeLossAttributableToCommonStockholdersBasicAndDiluted\"]',\n",
    "            '//us-gaap:NetIncomeLossAvailableToCommonStockholdersBasic',\n",
    "            '//*[local-name()=\"NetIncomeLossEPS\"]',\n",
    "            '//*[local-name()=\"NetLoss\"]'\n",
    "        ])\n",
    "\n",
    "        self.add_xpaths('eps_diluted', [\n",
    "            '//us-gaap:EarningsPerShareDiluted',\n",
    "            '//us-gaap:IncomeLossFromContinuingOperationsPerDilutedShare',\n",
    "            '//us-gaap:IncomeLossFromContinuingOperationsPerBasicAndDilutedShare',\n",
    "            '//*[contains(local-name(), \"Earnings\") and contains(local-name(), \"Per\") and contains(local-name(), \"Diluted\")]',\n",
    "            '//*[local-name()=\"IncomePerShareFromContinuingOperationsAvailableToCompanyStockholdersBasicAndDiluted\"]',\n",
    "            '//*[contains(local-name(), \"NetLossPerShare\")]',\n",
    "            '//*[contains(local-name(), \"NetIncome\") and contains(local-name(), \"Per\") and contains(local-name(), \"Diluted\")]',\n",
    "            '//*[local-name()=\"DilutedEarningsAttributableToStockholdersPerCommonShare\"]',\n",
    "            '//us-gaap:NetIncomeLossAvailableToCommonStockholdersDiluted',\n",
    "            '//*[contains(local-name(), \"PerCommonShareBasicAndDiluted\")]',\n",
    "            '//*[local-name()=\"NetIncomeLossAttributableToCommonStockholdersBasicAndDiluted\"]',\n",
    "            '//us-gaap:EarningsPerShareBasic',\n",
    "            '//*[local-name()=\"NetIncomeLossEPS\"]',\n",
    "            '//*[local-name()=\"NetLoss\"]'\n",
    "        ])\n",
    "\n",
    "        self.add_xpaths('dividend', [\n",
    "            '//us-gaap:CommonStockDividendsPerShareDeclared',\n",
    "            '//us-gaap:CommonStockDividendsPerShareCashPaid'\n",
    "        ])\n",
    "\n",
    "        # if dividend isn't found in doc, assume it's 0\n",
    "        self.add_value('dividend', 0.0)\n",
    "\n",
    "        self.add_xpaths('assets', [\n",
    "            '//us-gaap:Assets',\n",
    "            '//us-gaap:AssetsNet',\n",
    "            '//us-gaap:LiabilitiesAndStockholdersEquity'\n",
    "        ])\n",
    "\n",
    "        self.add_xpaths('cur_assets', [\n",
    "            '//us-gaap:AssetsCurrent'\n",
    "        ])\n",
    "\n",
    "        self.add_xpaths('cur_liab', [\n",
    "            '//us-gaap:LiabilitiesCurrent'\n",
    "        ])\n",
    "\n",
    "        self.add_xpaths('equity', [\n",
    "            '//*[local-name()=\"StockholdersEquityIncludingPortionAttributableToNoncontrollingInterest\" or local-name()=\"StockholdersEquity\"]',\n",
    "            '//*[local-name()=\"TotalCommonShareholdersEquity\"]',\n",
    "            '//*[local-name()=\"CommonShareholdersEquity\"]',\n",
    "            '//*[local-name()=\"CommonStockEquity\"]',\n",
    "            '//*[local-name()=\"TotalEquity\"]',\n",
    "            '//us-gaap:RetainedEarningsAccumulatedDeficit',\n",
    "            '//*[contains(local-name(), \"MembersEquityIncludingPortionAttributableToNoncontrollingInterest\")]',\n",
    "            '//us-gaap:CapitalizationLongtermDebtAndEquity',\n",
    "            '//*[local-name()=\"TotalCapitalization\"]'\n",
    "        ])\n",
    "\n",
    "        self.add_xpaths('cash', [\n",
    "            '//us-gaap:CashCashEquivalentsAndFederalFundsSold',\n",
    "            '//us-gaap:CashAndDueFromBanks',\n",
    "            '//us-gaap:CashAndCashEquivalentsAtCarryingValue',\n",
    "            '//us-gaap:Cash',\n",
    "            '//*[local-name()=\"CashAndCashEquivalents\"]',\n",
    "            '//*[contains(local-name(), \"CarryingValueOfCashAndCashEquivalents\")]',\n",
    "            '//*[contains(local-name(), \"CashCashEquivalents\")]',\n",
    "            '//*[contains(local-name(), \"CashAndCashEquivalents\")]'\n",
    "        ])\n",
    "\n",
    "        self.add_xpaths('cash_flow_op', [\n",
    "            '//us-gaap:NetCashProvidedByUsedInOperatingActivities',\n",
    "            '//us-gaap:NetCashProvidedByUsedInOperatingActivitiesContinuingOperations'\n",
    "        ])\n",
    "\n",
    "        self.add_xpaths('cash_flow_inv', [\n",
    "            '//us-gaap:NetCashProvidedByUsedInInvestingActivities',\n",
    "            '//us-gaap:NetCashProvidedByUsedInInvestingActivitiesContinuingOperations'\n",
    "        ])\n",
    "\n",
    "        self.add_xpaths('cash_flow_fin', [\n",
    "            '//us-gaap:NetCashProvidedByUsedInFinancingActivities',\n",
    "            '//us-gaap:NetCashProvidedByUsedInFinancingActivitiesContinuingOperations'\n",
    "        ])\n",
    "\n",
    "    def _get_symbol(self):\n",
    "        try:\n",
    "            filename = self.context['response'].url.split('/')[-1]\n",
    "            return filename.split('-')[0].upper()\n",
    "        except IndexError:\n",
    "            return None\n",
    "\n",
    "    def _get_doc_fiscal_year(self):\n",
    "        try:\n",
    "            fiscal_year = self.selector.xpath('//dei:DocumentFiscalYearFocus/text()')[0].extract()\n",
    "            return int(fiscal_year)\n",
    "        except (IndexError, ValueError):\n",
    "            return None\n",
    "\n",
    "    def _guess_fiscal_year(self, end_date, period_focus):\n",
    "        # Guess fiscal_year based on document end_date and period_focus\n",
    "        date = datetime.strptime(end_date, DATE_FORMAT)\n",
    "        month_ranges = {\n",
    "            'Q1': (2, 3, 4),\n",
    "            'Q2': (5, 6, 7),\n",
    "            'Q3': (8, 9, 10),\n",
    "            'FY': (11, 12, 1)\n",
    "        }\n",
    "        month_range = month_ranges.get(period_focus)\n",
    "\n",
    "        # Case 1: release Q1 around March, Q2 around June, ...\n",
    "        # This is what most companies do\n",
    "        if date.month in month_range:\n",
    "            if period_focus == 'FY' and date.month == 1:\n",
    "                return date.year - 1\n",
    "            return date.year\n",
    "\n",
    "        # How many days left before 10-K's release?\n",
    "        days_left_table = {\n",
    "            'Q1': 270,\n",
    "            'Q2': 180,\n",
    "            'Q3': 90,\n",
    "            'FY': 0\n",
    "        }\n",
    "        days_left = days_left_table.get(period_focus)\n",
    "\n",
    "        # Other cases, assume end_date.year of its FY report equals to\n",
    "        # its fiscal_year\n",
    "        if days_left is not None:\n",
    "            fy_date = date + timedelta(days=days_left)\n",
    "            return fy_date.year\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _get_doc_end_date(self):\n",
    "        # the document end date could come from URL or document content\n",
    "        # we need to guess which one is correct\n",
    "        url_date_str = self.context['response'].url.split('-')[-1].split('.')[0]\n",
    "        url_date = datetime.strptime(url_date_str, '%Y%m%d')\n",
    "        url_date_str = url_date.strftime(DATE_FORMAT)\n",
    "\n",
    "        try:\n",
    "            doc_date_str = self.selector.xpath('//dei:DocumentPeriodEndDate/text()')[0].extract()\n",
    "            doc_date = datetime.strptime(doc_date_str, DATE_FORMAT)\n",
    "        except (IndexError, ValueError):\n",
    "            return url_date.strftime(DATE_FORMAT)\n",
    "\n",
    "        context_date_strs = set(self.selector.xpath('//*[local-name()=\"context\"]//*[local-name()=\"endDate\"]/text()').extract())\n",
    "\n",
    "        date = url_date\n",
    "        if doc_date_str in context_date_strs:\n",
    "            date = doc_date\n",
    "\n",
    "        return date.strftime(DATE_FORMAT)\n",
    "\n",
    "    def _get_doc_type(self):\n",
    "        try:\n",
    "            return self.selector.xpath('//dei:DocumentType/text()')[0].extract().upper()\n",
    "        except (IndexError, ValueError):\n",
    "            return None\n",
    "\n",
    "    def _get_period_focus(self, doc_end_date):\n",
    "        try:\n",
    "            return self.selector.xpath('//dei:DocumentFiscalPeriodFocus/text()')[0].extract().strip().upper()\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            doc_yr = doc_end_date.split('-')[0]\n",
    "            yr_end_date = self.selector.xpath('//dei:CurrentFiscalYearEndDate/text()')[0].extract()\n",
    "            yr_end_date = yr_end_date.replace('--', doc_yr + '-')\n",
    "        except IndexError:\n",
    "            return None\n",
    "\n",
    "        doc_end_date = datetime.strptime(doc_end_date, '%Y-%m-%d')\n",
    "        yr_end_date = datetime.strptime(yr_end_date, '%Y-%m-%d')\n",
    "        delta_days = (yr_end_date - doc_end_date).days\n",
    "\n",
    "        if delta_days > -45 and delta_days < 45:\n",
    "            return 'FY'\n",
    "        elif (delta_days <= -45 and delta_days > -135) or delta_days > 225:\n",
    "            return 'Q1'\n",
    "        elif (delta_days <= -135 and delta_days > -225) or (delta_days > 135 and delta_days <= 225):\n",
    "            return 'Q2'\n",
    "        elif delta_days <= -225 or (delta_days > 45 and delta_days <= 135):\n",
    "            return 'Q3'\n",
    "\n",
    "        return 'FY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spiders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "from scrapy.linkextractors import LinkExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class URLGenerator(object):\n",
    "\n",
    "    def __init__(self, symbols, start_date='', end_date='', start=0, count=None):\n",
    "        end = start + count if count is not None else None\n",
    "        self.symbols = symbols[start:end]\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "\n",
    "    def __iter__(self):\n",
    "        url = 'http://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=%s&type=10-&dateb=%s&datea=%s&owner=exclude&count=300'\n",
    "        for symbol in self.symbols:\n",
    "            yield (url % (symbol, self.end_date, self.start_date))\n",
    "            \n",
    "class EdgarSpider(CrawlSpider):\n",
    "\n",
    "    name = 'edgar'\n",
    "    allowed_domains = ['sec.gov']\n",
    "\n",
    "    rules = (\n",
    "        Rule(LinkExtractor(allow=('/Archives/edgar/data/[^\\\"]+\\-index\\.htm',))),\n",
    "        Rule(LinkExtractor(allow=('/Archives/edgar/data/[^\\\"]+/[A-Za-z]+\\-\\d{8}\\.xml',)), callback='parse_10qk'),\n",
    "    )\n",
    "    def __init__(self, **kwargs):\n",
    "        super(EdgarSpider, self).__init__(**kwargs)\n",
    "\n",
    "        symbols_arg = kwargs.get('symbols')\n",
    "        start_date = kwargs.get('startdate', '')\n",
    "        end_date = kwargs.get('enddate', '')\n",
    "        limit_arg = kwargs.get('limit', '')\n",
    "\n",
    "        check_date_arg(start_date, 'startdate')\n",
    "        check_date_arg(end_date, 'enddate')\n",
    "        start, count = parse_limit_arg(limit_arg)\n",
    "\n",
    "        if symbols_arg:\n",
    "            if os.path.exists(symbols_arg):\n",
    "                # get symbols from a text file\n",
    "                symbols = load_symbols(symbols_arg)\n",
    "            else:\n",
    "                # inline symbols in command\n",
    "                symbols = symbols_arg.split(',')\n",
    "            self.start_urls = URLGenerator(symbols, start_date, end_date, start, count)\n",
    "        else:\n",
    "            self.start_urls = []\n",
    "\n",
    "    def parse_10qk(self, response):\n",
    "        '''Parse 10-Q or 10-K XML report.'''\n",
    "        loader = ReportItemLoader(response=response)\n",
    "        item = loader.load_item()\n",
    "\n",
    "        if 'doc_type' in item:\n",
    "            doc_type = item['doc_type']\n",
    "            if doc_type in ('10-Q', '10-K'):\n",
    "                return item\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=GOOG&type=10-&dateb=&datea=&owner=exclude&count=300', 'http://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=FB&type=10-&dateb=&datea=&owner=exclude&count=300', 'http://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=AAPL&type=10-&dateb=&datea=&owner=exclude&count=300']\n"
     ]
    }
   ],
   "source": [
    "spider = EdgarSpider(symbols='GOOG,FB,AAPL')\n",
    "urls = list(spider.start_urls)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
